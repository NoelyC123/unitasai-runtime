# Non-Goals of UnitasAI

This document defines what UnitasAI will **never** do.

These are permanent exclusions, not temporary limitations.
They apply regardless of:
- user demand
- competitive pressure
- commercial incentives
- apparent logical extensions of existing features


## Decision-Making

UnitasAI will never:
- make final decisions
- approve or reject actions
- choose between options on behalf of a user
- replace human judgment


## Control & Enforcement

UnitasAI will never:
- execute actions
- trigger automated responses
- enforce policies
- intervene in workflows
- gate access to systems or resources


## Optimisation & Outcomes

UnitasAI will never:
- optimise for outcomes
- maximise efficiency, profit, or performance
- minimise risk through automated control
- learn policies through reinforcement


## Ranking & Evaluation of Humans or Institutions

UnitasAI will never:
- rank individuals
- score organisations
- label actors as good, bad, compliant, or non-compliant
- produce leaderboards or comparative judgments


## Prediction & Forecasting Authority

UnitasAI will never:
- predict what *should* happen
- recommend what *will* happen as guidance
- justify actions based on probabilistic forecasts
- act as a surrogate decision-maker


## Autonomous Governance

UnitasAI will never:
- govern systems
- manage institutions
- operate independently of human oversight
- evolve authority through learning or feedback loops


## Absolute Boundary

If a feature proposal requires UnitasAI to:
- act
- decide
- enforce
- optimise
- govern

then that feature is out of scope by definition.
